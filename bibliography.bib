@article{li2019,
	abstract = {Data lying in a high dimensional ambient space are commonly thought to have a much lower intrinsic dimension. In particular, the data may be concentrated near a lower-dimensional manifold. There is a rich literature focused on approximating the unknown manifold, and in exploiting such approximations in clustering, data compression, and building of predictive models. Most of the literature relies on approximating manifolds using a locally linear, and potentially multiscale, dictionary. In this article, we propose a simple and general alternative, which instead uses pieces of spheres, or spherelets, to locally approximate the unknown manifold. Theory is developed showing that spherelets can produce lower covering numbers and MSEs for many manifolds. We develop spherical principal components analysis (SPCA). Results relative to state-of-the-art competitors show gains in ability to accurately approximate the manifold with fewer components. In addition, unlike most competitors, our approach can be used for data denoising and can efficiently embed new data without retraining. The methods are illustrated with standard toy manifold learning examples, and applications to multiple real data sets.},
	author = {Didong Li, Minerva Mukhopadhyay, and David B Dunson},
	journal = {arXiv},
	date = {2019-02-25},
	title = {{Efficient Manifold Approximation with Spherelets}},
	year = {2019}
}

@article{li2017,
	abstract = {Data lying in a high-dimensional ambient space are commonly thought to have a much lower intrinsic dimension. In particular, the data may be concentrated near a lower dimensional subspace or manifold. There is an immense literature focused on approximating the unknown subspace, and in exploiting such approximations in clustering, data compression, and build-ing of predictive models. Most of the literature relies on approximating subspaces using a locally linear, and potentially multiscale, dictionary. In this article, we propose a simple and general alternative, which instead uses pieces of spheres, or spherelets, to locally approximate the unknown subspace. Building on this idea, we develop a simple and computationally efficient algorithm for subspace learning and clustering. Results relative to state-of-the-art competitors show dramatic gains in ability to accurately approximate the subspace with orders of magnitude fewer components. This leads to substantial gains in data compressibility, few clusters and hence better interpretability, and much lower MSE based on smallt o moderate sample sizes. Basic theory on approximation accuracy is presented, and the methods are applied to multiple examples},
	author = {Didong Li and David B Dunson},
	organization = {ResearchGate},
	journal = {arXiv},
	date = {2017-06-26},
	title = {{Efficient Manifold and Subspace Approximations with Spherelets}},
	year = {2017}
}

@online{github,
	author = {mmukhopadhyay},
	title = {{Efficient Manifold Learning Using Spherelets}},
	organization = {Github},
	date = {2019-04-09}
}